{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = 'digit-recognizer/'\n",
    "TRAIN_CSV = 'train.csv' \n",
    "TEST_CSV = 'test.csv'\n",
    "\n",
    "CLASSES = 10\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 6000\n",
    "LR = 0.0005\n",
    "\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(os.path.join(IMAGE_FOLDER, TRAIN_CSV))\n",
    "test_dataset = pd.read_csv(os.path.join(IMAGE_FOLDER, TEST_CSV))\n",
    "set_lenght = int(len(dataset) * 0.9)\n",
    "\n",
    "train_dataset = np.array(dataset[:set_lenght])\n",
    "val_dataset = np.array(dataset[set_lenght:])\n",
    "\n",
    "X_test = np.array(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37800, 784), (37800,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_dataset[:, 1:]\n",
    "y_train = train_dataset[:, 0]\n",
    "\n",
    "X_val = val_dataset[:, 1:]\n",
    "y_val = val_dataset[:, 0]\n",
    "\n",
    "\n",
    "X_train.shape, y_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array of one-hot encoded vectors from vector of labels\n",
    "def one_hot(vector):\n",
    "    one_hot = np.zeros((vector.shape[0], CLASSES), dtype = int)\n",
    "    one_hot[np.arange(vector.size), vector] = 1\n",
    "    return one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, label, nrows, ncolumns):\n",
    "    images = images.T\n",
    "    num_images = images.shape[1]\n",
    "    \n",
    "    _, axes = plt.subplots(nrows, ncolumns, figsize=(ncolumns*3, nrows*3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    if nrows * ncolumns < num_images:\n",
    "        print(f\"Not all images are shown. Images provided: {num_images}. Please change number of columns of rows\")\n",
    "\n",
    "    for i in range(nrows * ncolumns):\n",
    "        one_hot_enc = one_hot(label[i].reshape(1,1))\n",
    "\n",
    "        if num_images < i +1:\n",
    "            axes[i].imshow(np.zeros((28, 28)))\n",
    "            axes[i].set_title(f\"Empty\")\n",
    "        else:   \n",
    "            axes[i].imshow(images[:, i].reshape(28, 28))\n",
    "            axes[i].set_title(f\"Label:{label[i].item()}\\n One-Hot: {one_hot_enc.squeeze()}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not all images are shown. Images provided: 16. Please change number of columns of rows\n"
     ]
    }
   ],
   "source": [
    "show_images(X_train[:16], y_train[:12], 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    A = np.exp(x - np.max(x, axis=0))\n",
    "    B = np.sum(A, axis=0)\n",
    "    return A / B\n",
    "\n",
    "def cross_entropy_loss(predictions, targets):\n",
    "    return -np.sum(targets * np.log(predictions + 1e-9)) / predictions.shape[1]\n",
    "\n",
    "def cross_entropy_loss_derivative(predictions, targets):\n",
    "    return predictions - targets\n",
    "\n",
    "def predictions(prediction):\n",
    "    return np.argmax(prediction, 0)\n",
    "\n",
    "def accuracy(prediction, target_label):\n",
    "    return np.sum(prediction == target_label) / target_label.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(input_size=784, hidden_layer_size=392, output_size=10):\n",
    "    w_0 = np.random.uniform(-0.5, 0.5, (hidden_layer_size, input_size))\n",
    "    b_0 = np.zeros((hidden_layer_size, 1))\n",
    "\n",
    "    w_1 = np.random.uniform(-0.5, 0.5, (output_size, hidden_layer_size))\n",
    "    b_1 = np.zeros((output_size, 1))\n",
    "\n",
    "    return w_0, b_0, w_1, b_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(X_data, y_data, batch_size = 64, shuffle=False):\n",
    "    batches = []\n",
    "    dataset_len = X_data.shape[0]\n",
    "    num_batches = dataset_len // batch_size\n",
    "\n",
    "    if dataset_len % batch_size != 0 : num_batches += 1 \n",
    "\n",
    "\n",
    "    start = 0\n",
    "    end = batch_size\n",
    "\n",
    "    if shuffle:\n",
    "        X_data, y_data = utils.shuffle(X_data, y_data)\n",
    "\n",
    "    for _ in range(num_batches):\n",
    "        if end > dataset_len: end = dataset_len\n",
    "        \n",
    "        images = X_data[start:end]\n",
    "        labels = y_data[start:end]\n",
    "\n",
    "        start = end\n",
    "        end += batch_size\n",
    "\n",
    "        batches.append((images, labels))\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, w_0, b_0, w_1, b_1):\n",
    "    image, label = X_train.T, y_train\n",
    "    \n",
    "    # initialization of input layer and target\n",
    "    target = one_hot(label).T\n",
    "    input_layer = image\n",
    "\n",
    "    # forward propagation\n",
    "    #1\n",
    "    hidden_layer = w_0 @ input_layer + b_0\n",
    "\n",
    "    #2\n",
    "    logits = w_1 @ hidden_layer + b_1\n",
    "    output = softmax(logits)\n",
    "\n",
    "    # Cost function\n",
    "    loss = cross_entropy_loss(output, target)\n",
    "    pred = predictions(output)\n",
    "    acc = accuracy(pred, label)\n",
    "        \n",
    "    # backpropagation \n",
    "    #1\n",
    "    delta_output_hidden = cross_entropy_loss_derivative(output, target)\n",
    "    w_1_grad = delta_output_hidden @ hidden_layer.T\n",
    "    b_1_grad = np.sum(delta_output_hidden, axis=1, keepdims=True)\n",
    "    \n",
    "    #2\n",
    "    delta_hidden_input = w_1.T @ delta_output_hidden\n",
    "    w_0_grad = delta_hidden_input @ input_layer.T\n",
    "    b_0_grad = np.sum(delta_hidden_input, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "    # Gradient clipping to avoid exploding gradients\n",
    "    w_1_grad = np.clip(w_1_grad, -1, 1)\n",
    "    b_1_grad = np.clip(b_1_grad, -1, 1)\n",
    "    w_0_grad = np.clip(w_0_grad, -1, 1)\n",
    "    b_0_grad = np.clip(b_0_grad, -1, 1)\n",
    "\n",
    "    w_1 += -LR * w_1_grad\n",
    "    b_1 += -LR * b_1_grad\n",
    "    w_0 += -LR * w_0_grad\n",
    "    b_0 += -LR * b_0_grad\n",
    "\n",
    "\n",
    "    return w_0, b_0, w_1, b_1, loss, acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(X_val, y_val, w_0, b_0, w_1, b_1):\n",
    "    image, label = X_val.T, y_val\n",
    "    \n",
    "    # initialization of input layer and target\n",
    "    target = one_hot(label).T\n",
    "    input_layer = image\n",
    "\n",
    "    # forward propagation\n",
    "    #1\n",
    "    hidden_layer = w_0 @ input_layer + b_0\n",
    "\n",
    "    #2\n",
    "    logits = w_1 @ hidden_layer + b_1\n",
    "    output = softmax(logits)\n",
    "\n",
    "    # Cost function\n",
    "    loss = cross_entropy_loss(output, target)\n",
    "    pred = predictions(output)\n",
    "    acc = accuracy(pred, label)\n",
    "\n",
    "    return loss, acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_digit_label(X_test, w_0, b_0, w_1, b_1):\n",
    "    image = X_test.T\n",
    "    input_layer = image\n",
    "\n",
    "    # forward propagation\n",
    "    #1\n",
    "    hidden_layer = w_0 @ input_layer + b_0\n",
    "\n",
    "    #2\n",
    "    logits = w_1 @ hidden_layer + b_1\n",
    "    output = softmax(logits)\n",
    "\n",
    "    # Cost function\n",
    "    pred = predictions(output)\n",
    "\n",
    "    return X_test, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3075645072.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 25\u001b[0;36m\u001b[0m\n\u001b[0;31m    batch_accuracy.append(acc)k\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "epoch_train_loss = []\n",
    "epoch_train_accuracy = []\n",
    "epoch_val_loss = []\n",
    "epoch_val_accuracy = []\n",
    "\n",
    "train_dataloader = dataloader(X_train, y_train, BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = dataloader(X_val, y_val, BATCH_SIZE)\n",
    "\n",
    "w_0, b_0, w_1, b_1 = init_params(input_size=784, hidden_layer_size=392, output_size=CLASSES)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    batch_loss = []\n",
    "    batch_accuracy = []\n",
    "    batch_val_loss = []\n",
    "    batch_val_accuracy = []\n",
    "\n",
    "    #training\n",
    "    for batch in train_dataloader:\n",
    "        images, labels = batch\n",
    "        val_loss, val_acc  = validation(images, labels, w_0, b_0, w_1, b_1)\n",
    "        w_0, b_0, w_1, b_1, loss, acc  = train(images, labels, w_0, b_0, w_1, b_1)\n",
    "        print(val_loss, val_acc)\n",
    "\n",
    "        batch_loss.append(loss)\n",
    "        batch_accuracy.append(acc)\n",
    "\n",
    "    #validation\n",
    "    for batch in val_dataloader:\n",
    "        val_images, val_labels = batch\n",
    "        val_loss, val_acc  = validation(val_images, val_labels , w_0, b_0, w_1, b_1)\n",
    "\n",
    "        batch_val_loss.append(val_loss)\n",
    "        batch_val_accuracy.append(val_acc)\n",
    "        \n",
    "\n",
    "    # metrics\n",
    "    epoch_train_loss.append(np.mean(batch_loss))\n",
    "    epoch_train_accuracy.append(np.mean(batch_accuracy)*100)\n",
    "    epoch_val_loss.append(np.mean(batch_val_loss))\n",
    "    epoch_val_accuracy.append(np.mean(batch_val_accuracy)*100)\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        print(f\"-- Train Loss {epoch_train_loss[epoch]:.4f} - Train Accuracy {epoch_train_accuracy[epoch]:.4f}\")   \n",
    "        print(f\"-- Validation Loss {epoch_val_loss[epoch]:.4f} - Validation Accuracy {epoch_val_accuracy[epoch]:.4f}\\n\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graphs(train_loss, train_accuracy, val_loss, val_accuracy):\n",
    "    _, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    axes[0].plot(train_loss)\n",
    "    axes[0].plot(val_loss)\n",
    "    axes[0].set_title(f\"Loss\")\n",
    "    axes[0].legend([\"train\", \"val\"])                    \n",
    "    axes[1].plot(train_accuracy)\n",
    "    axes[1].plot(val_accuracy)\n",
    "    axes[1].set_title(f\"Accuracy\")\n",
    "    axes[1].legend([\"train\", \"val\"])\n",
    "\n",
    "\n",
    "show_graphs(epoch_train_loss, epoch_train_accuracy, epoch_val_loss, epoch_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, pred = predict_digit_label(X_test[140:172], w_0, b_0, w_1, b_1)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(images, pred, 4, 8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
